% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/vglmer_regression.R
\name{vglmer_control}
\alias{vglmer_control}
\title{Control for vglmer}
\usage{
vglmer_control(
  iterations = 1000,
  prior_variance = "hw",
  factorization_method = c("strong", "partial", "weak"),
  tolerance_elbo = 1e-08,
  tolerance_parameters = 1e-05,
  prevent_degeneracy = FALSE,
  force_whole = TRUE,
  verbose_time = TRUE,
  parameter_expansion = "translation",
  do_timing = FALSE,
  debug_param = FALSE,
  return_data = FALSE,
  linpred_method = "joint",
  vi_r_method = "VEM",
  vi_r_val = NA,
  do_SQUAREM = TRUE,
  verify_columns = FALSE,
  debug_ELBO = FALSE,
  print_prog = NULL,
  quiet = T,
  quiet_rho = TRUE,
  debug_px = FALSE,
  px_method = "dynamic",
  px_numerical_it = 10,
  hw_INNER = 10,
  init = "EM_FE"
)
}
\arguments{
\item{iterations}{Number of iterations for the model.}

\item{prior_variance}{Options are \code{hw}, \code{jeffreys},
\code{mcmcglmm}, \code{mvD}, \code{mean_exists}, limit, and uniform. The
default (\code{hw}) is the Huang-Wand (2013) prior whose hyper-parameters
are nu = 2 and A = 5.

Otherwise, the prior is an Inverse Wishart with the
following parameters where d is the dimensionality of the random effect.
\itemize{
\item hw: Huang and Wand (2013) with \eqn{\nu_j = 2} and \eqn{A_{j,k} = 5}
\item mean_exists: IW(d + 1, I)
\item jeffreys: IW(0, 0)
\item mcmcglmm: IW(0, I)
\item mvD: IW(-d, I)
\item limit: IW(d - 1, 0)
\item uniform: IW(-[d+1], 0)
}
The model may fail to be estimable if an improper prior is used. In that
case, use either \code{hw} or \code{mean_exists}.}

\item{factorization_method}{The factorization method to use. Default of
\code{strong}. Described in detail in Goplerud (2022a). \code{strong},
\code{partial}, and \code{weak} correspond to Schemes I, II, and III
respectively. "weak" should have best performance but is slowest.}

\item{tolerance_elbo}{Change in ELBO to stop algorithm.}

\item{tolerance_parameters}{Change in value of any parameter to stop
algorithm.}

\item{prevent_degeneracy}{Ignored for the moment.}

\item{force_whole}{Require whole numbers. Set to FALSE to allow "quasi-binomial".}

\item{verbose_time}{Print time for each step (debugging only)}

\item{parameter_expansion}{Default of \code{translation}  (see Goplerud 2022b).
Accepts either \code{translation}, \code{mean}, or \code{none}. \code{mean}
should be employed if \code{translation} is not enabled or is too
computationally expensive.}

\item{do_timing}{Estimate timing with tictoc}

\item{debug_param}{Debug parameter convergence.}

\item{return_data}{Return the design (X,Z) for debugging afterwards.}

\item{linpred_method}{Method for updating means of beta and alpha. "joint" is best.}

\item{vi_r_method}{Type of estimate for "r"; at moment, "fixed" (provide r),
"VEM" (treat r as point estimate; default);
"Laplace" (estimate using Laplace approximation described in the Addendum on GitHub); or "delta"
(experimential).}

\item{vi_r_val}{For fixed "r", which value?}

\item{do_SQUAREM}{Accelerate method using SQUAREM (Varadhan and Roland 2008).}

\item{verify_columns}{Verify that all columns are drawn from the data.frame itself.}

\item{debug_ELBO}{Debug ELBO trajectory.}

\item{print_prog}{Print after print_prog iterations to show progress.}

\item{quiet}{Don't print noisy intermediate output.}

\item{quiet_rho}{Debug parameter expansion by printing updates}

\item{debug_px}{Debug parameter expansion by verifying ELBO}

\item{px_method}{For \code{translation} expansion, how to update? "dynamic"
tries OSL and then backup numerical improvement via L-BFGS-B.}

\item{px_numerical_it}{How many steps of L-BFGS-B are used to improve?}

\item{hw_INNER}{For HW prior, how many "loops" between optimizing the
Inverse-Wishart and Inverse-Gamma parameters are done at each iteration?}

\item{init}{Initialization method can be one of four options: "EM_FE" sets
the random effects to zero, estimates the fixed effects and initializes the
model. "EM" initializes the model with a ridge regression with a guess as
to the random effect variance. "zero" initializes the variational means at
zero. "random" initializes randomly.}
}
\description{
Provides a set of control arguments to vglmer
}
\references{
Goplerud, Max. 2022a. "Fast and Accurate Estimation of Non-Nested Binomial
Hierarchical Models Using Variational Inference." Bayesian Analysis. 17(2):
623-650.

Goplerud, Max. 2022b. "Re-Evaluating Machine Learning for MRP Given the
Comparable Performance of (Deep) Hierarchical Models." Working Paper.

Huang, Alan, and Matthew P. Wand. 2013. "Simple Marginally Noninformative
Prior Distributions for Covariance Matrices." Bayesian Analysis.
8(2):439-452.

Varadhan, Ravi, and Christophe Roland. 2008. "Simple and Globally Convergent
Methods for Accelerating the Convergence of any EM Algorithm." Scandinavian
Journal of Statistics. 35(2): 335-353.
}
